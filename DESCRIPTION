Package: piecemaker
Title: Tools for Preparing Text for Tokenizers
Version: 1.0.0
Authors@R: c(
    person(given = "Jon",
           family = "Harmon",
           role = c("aut", "cre"),
           email = "jonthegeek@gmail.com",
           comment = c(ORCID = "0000-0003-4781-4346")),
    person(given = "Jonathan",
           family = "Bratt",
           role = c("aut"),
           email = "jonathan.bratt@macmillan.com",
           comment = c(ORCID = "0000-0003-2859-0076")),
    person(given = "Bedford Freeman & Worth Pub Grp LLC DBA Macmillan Learning", 
           role = c("cph"))
    )
Description: Tokenizers break text into pieces that are more usable by machine 
    learning models. Many tokenizers share some preparation steps. This package
    provides those shared steps, along with a simple tokenizer.
License: Apache License (>= 2)
Encoding: UTF-8
RoxygenNote: 7.1.1
URL: https://github.com/macmillancontentscience/piecemaker
BugReports: https://github.com/macmillancontentscience/piecemaker/issues
Suggests: testthat (>= 3.0.0)
Config/testthat/edition: 3
Imports: purrr, rlang (>= 0.4.2), stringi, stringr
Depends: R (>= 2.10)
NeedsCompilation: no
Packaged: 2021-08-05 22:01:09 UTC; jonth
Author: Jon Harmon [aut, cre] (<https://orcid.org/0000-0003-4781-4346>),
  Jonathan Bratt [aut] (<https://orcid.org/0000-0003-2859-0076>),
  Bedford Freeman & Worth Pub Grp LLC DBA Macmillan Learning [cph]
Maintainer: Jon Harmon <jonthegeek@gmail.com>
Repository: CRAN
Date/Publication: 2021-08-06 17:50:06 UTC
